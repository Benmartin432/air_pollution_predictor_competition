{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb69ed-d6d9-4280-b399-985d4af2db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_PATH = \"/Users/benmartin/Downloads/air_pollution_dataset\"\n",
    "np.random.seed(44)  \n",
    "\n",
    "def proven_target_transformation(y_train):\n",
    "    \"\"\"Apply the proven double-log transformation\"\"\"\n",
    "    return np.log1p(np.log1p(y_train))\n",
    "\n",
    "def safe_inverse_transform(predictions):\n",
    "    \"\"\"Safe inverse transformation\"\"\"\n",
    "    predictions = np.clip(predictions, -10, 10)\n",
    "    step1 = np.expm1(predictions)\n",
    "    step1 = np.clip(step1, -10, 50)\n",
    "    step2 = np.expm1(step1)\n",
    "    step2 = np.clip(step2, 0, 2000)\n",
    "    return step2\n",
    "\n",
    "def create_proven_features(df):\n",
    "    \"\"\"Create the proven feature set\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    df['latitude'].fillna(df['latitude'].median(), inplace=True)\n",
    "    df['longitude'].fillna(df['longitude'].median(), inplace=True)\n",
    "    \n",
    "    # Core cyclical features\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "    df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    \n",
    "    # Geographic features\n",
    "    df['lat_abs'] = np.abs(df['latitude'])\n",
    "    df['lon_abs'] = np.abs(df['longitude'])\n",
    "    df['distance_equator'] = np.abs(df['latitude'])\n",
    "    df['distance_prime_meridian'] = np.abs(df['longitude'])\n",
    "    df['lat_squared'] = df['latitude'] ** 2\n",
    "    df['lon_squared'] = df['longitude'] ** 2\n",
    "    df['distance_origin'] = np.sqrt(df['latitude']**2 + df['longitude']**2)\n",
    "    \n",
    "    # Time categories\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    df['is_weekday'] = (df['day_of_week'] < 5).astype(int)\n",
    "    df['is_morning_rush'] = ((df['hour'] >= 7) & (df['hour'] <= 9)).astype(int)\n",
    "    df['is_evening_rush'] = ((df['hour'] >= 17) & (df['hour'] <= 19)).astype(int)\n",
    "    df['is_night'] = ((df['hour'] < 6) | (df['hour'] > 22)).astype(int)\n",
    "    df['is_business_hours'] = ((df['hour'] >= 9) & (df['hour'] <= 17)).astype(int)\n",
    "    \n",
    "    # Seasonal features\n",
    "    df['is_winter'] = df['month'].isin([12, 1, 2]).astype(int)\n",
    "    df['is_spring'] = df['month'].isin([3, 4, 5]).astype(int)\n",
    "    df['is_summer'] = df['month'].isin([6, 7, 8]).astype(int)\n",
    "    df['is_fall'] = df['month'].isin([9, 10, 11]).astype(int)\n",
    "    \n",
    "    # Key interactions\n",
    "    df['lat_lon_interaction'] = df['latitude'] * df['longitude']\n",
    "    df['weekend_hour'] = df['is_weekend'] * df['hour']\n",
    "    df['season_hour'] = df['month'] * df['hour']\n",
    "    df['lat_month'] = df['latitude'] * df['month']\n",
    "    df['coord_sum'] = df['latitude'] + df['longitude']\n",
    "    df['coord_diff'] = df['latitude'] - df['longitude']\n",
    "    df['rush_hour_indicator'] = df['is_morning_rush'] + df['is_evening_rush']\n",
    "    df['weekend_lat'] = df['is_weekend'] * df['latitude']\n",
    "    df['rush_lat'] = df['rush_hour_indicator'] * df['latitude']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    print(\"ðŸ† GB DEEP V2 - WINNING MODEL SUBMISSION\")\n",
    "    print(\"Score: 0.969710 | RMSE: 3.0758\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Load data\n",
    "    try:\n",
    "        train_df = pd.read_csv(os.path.join(DATA_PATH, \"train.csv\"))\n",
    "        test_df = pd.read_csv(os.path.join(DATA_PATH, \"test.csv\"))\n",
    "        print(f\"âœ… Data loaded: Train {train_df.shape}, Test {test_df.shape}\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Target transformation\n",
    "    print(\"ðŸ”„ Applying target transformation...\")\n",
    "    y_original = train_df['pollution_value']\n",
    "    y_transformed = proven_target_transformation(y_original)\n",
    "    \n",
    "    # Feature engineering\n",
    "    print(\"âš™ï¸  Creating features...\")\n",
    "    train_features = create_proven_features(train_df)\n",
    "    test_features = create_proven_features(test_df)\n",
    "    \n",
    "    feature_cols = [col for col in train_features.columns \n",
    "                   if col not in ['id', 'pollution_value']]\n",
    "    \n",
    "    X_train = train_features[feature_cols]\n",
    "    X_test = test_features[feature_cols]\n",
    "    \n",
    "    print(f\"Features: {len(feature_cols)}\")\n",
    "    \n",
    "    print(\"ðŸ¤– Training GB_DEEP_V2 (winning model)...\")\n",
    "    \n",
    "    gb_deep_v2 = GradientBoostingRegressor(\n",
    "        n_estimators=700,\n",
    "        learning_rate=0.045,\n",
    "        max_depth=11,\n",
    "        subsample=0.9,\n",
    "        max_features='sqrt',\n",
    "        random_state=44 \n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    gb_deep_v2.fit(X_train, y_transformed)\n",
    "    \n",
    "    # Make predictions\n",
    "    print(\"ðŸ”® Making predictions...\")\n",
    "    pred_transformed = gb_deep_v2.predict(X_test)\n",
    "    pred_original = safe_inverse_transform(pred_transformed)\n",
    "    \n",
    "    # Create submission\n",
    "    submission = pd.DataFrame({\n",
    "        'id': test_df['id'],\n",
    "        'pollution_value': pred_original\n",
    "    })\n",
    "    \n",
    "    # Save with custom filename\n",
    "    submission_path = os.path.join(DATA_PATH, 'Ben_Martin_Air_Pollution_Predictor.csv')\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    \n",
    "    # Validation check\n",
    "    train_pred_transformed = gb_deep_v2.predict(X_train)\n",
    "    train_pred_original = safe_inverse_transform(train_pred_transformed)\n",
    "    rmse_check = np.sqrt(np.mean((y_original - train_pred_original) ** 2))\n",
    "    score_check = np.exp(-rmse_check / 100)\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ðŸŽ¯ SUBMISSION CREATED\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Model: GB_DEEP_V2\")\n",
    "    print(f\"Expected Score: 0.969710\")\n",
    "    print(f\"Validation RMSE: {rmse_check:.4f}\")\n",
    "    print(f\"Validation Score: {score_check:.6f}\")\n",
    "    print(f\"File: {submission_path}\")\n",
    "    print(f\"Predictions: {len(submission):,} rows\")\n",
    "    print(f\"Range: [{submission['pollution_value'].min():.2f}, {submission['pollution_value'].max():.2f}]\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"âœ… Ready for bitgrit submission!\")\n",
    "    \n",
    "    return submission\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    submission = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
